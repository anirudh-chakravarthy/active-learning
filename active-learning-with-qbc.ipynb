{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream and Pool Active Learning using QBC Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Breast Cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "x, y = fetch_covtype(return_X_y=True)\n",
    "NUM_CLASSES = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing, scale features between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the whole dataset in train & test splits\n",
    "x, _, y, _ = train_test_split(x, y, test_size = 0.70, random_state = 4) # discard because data is huge\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.40, random_state = 4)\n",
    "\n",
    "# further divide the train data in labelled & unlabelled data\n",
    "# retain only 10% of labelled points for training\n",
    "NUM_EXAMPLES = len(X_train)\n",
    "X_labelled, X_unlabelled, y_labelled, y_oracle = train_test_split(X_train, y_train, test_size = 0.90, random_state = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query By Committee\n",
    "Committee used:\n",
    "- Decision Tree Classifier\n",
    "- Random Forest Classifier\n",
    "- Gaussian NB\n",
    "- K Neighbors Classifier\n",
    "- Ada Boost Classifier\n",
    "\n",
    "Disagreement measures used:\n",
    "- Vote entropy\n",
    "- KL Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "committee = []\n",
    "committee.append(DecisionTreeClassifier())\n",
    "committee.append(RandomForestClassifier())\n",
    "committee.append(GaussianNB())\n",
    "committee.append(KNeighborsClassifier())\n",
    "committee.append(AdaBoostClassifier())\n",
    "\n",
    "NUM_COMMITTEE_MEMBERS = len(committee)\n",
    "\n",
    "for i in range(NUM_COMMITTEE_MEMBERS):\n",
    "    committee[i].fit(X_labelled, y_labelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qbc(committee, measure, ALtype, labelPercent):\n",
    "    \n",
    "    if ALtype == \"stream\":\n",
    "        queriedData, newLabels = [], []\n",
    "        # stream of points - one by one\n",
    "        for i in range(len(X_unlabelled)):\n",
    "            predictions = []\n",
    "            # each committee member gives their prediction\n",
    "            for j in range(NUM_COMMITTEE_MEMBERS):\n",
    "                committee_model = committee[j]\n",
    "                predictions.append(committee_model.predict(X_unlabelled[i].reshape(1, -1)))\n",
    "            # vote entropy based disagreement\n",
    "            if measure == \"voteEntropy\":\n",
    "                entropy = 0\n",
    "                # finding counts for each class\n",
    "                for k in range(NUM_CLASSES):\n",
    "                    count = predictions.count(k)\n",
    "                    # no entropy if vote doesn't exist\n",
    "                    if count == 0:\n",
    "                        continue\n",
    "                    entropy -= (count / NUM_COMMITTEE_MEMBERS) * np.log2(count / NUM_COMMITTEE_MEMBERS)\n",
    "                if entropy > 0.9:\n",
    "                    queriedData.append(X_unlabelled[i])\n",
    "                    newLabels.append(y_oracle[i])\n",
    "            # KL Divergence based disagreement   \n",
    "            elif measure == \"KLDivergence\":\n",
    "                kld = 0\n",
    "                # finding counts for each class\n",
    "                for k in range(NUM_CLASSES):\n",
    "                    count = predictions.count(k)\n",
    "                    # no KLD if vote doesn't exist\n",
    "                    if count == 0:\n",
    "                        continue\n",
    "                    kld -= count * np.log2(count / NUM_COMMITTEE_MEMBERS)\n",
    "                if kld > 7:\n",
    "                    queriedData.append(X_unlabelled[i])\n",
    "                    newLabels.append(y_oracle[i])\n",
    "            else:\n",
    "                assert False, \"Disagreement measure not implemented\"\n",
    "        return np.asarray(queriedData), np.asarray(newLabels)\n",
    "            \n",
    "        \n",
    "    elif ALtype == \"pool\":\n",
    "        predictions = []\n",
    "        disagreement = []\n",
    "        num_queries = int(NUM_EXAMPLES * labelPercent)\n",
    "        for k in range(NUM_COMMITTEE_MEMBERS):\n",
    "            predictions.append(committee[k].predict(X_unlabelled))\n",
    "        predictions = np.asarray(predictions)\n",
    "        for i in range(len(X_unlabelled)):\n",
    "            instanceDisagreement = 0\n",
    "            for j in range(NUM_CLASSES):\n",
    "                count = sum(predictions[:, i] == (j + 1))\n",
    "                # no contibution for classes not present in prediction\n",
    "                if count == 0:\n",
    "                    continue\n",
    "                if measure == \"voteEntropy\":\n",
    "                    instanceDisagreement -= (count / NUM_COMMITTEE_MEMBERS) * np.log2(count / NUM_COMMITTEE_MEMBERS)\n",
    "                elif measure == \"KLDivergence\":\n",
    "                    instanceDisagreement -= count * np.log2(count / NUM_COMMITTEE_MEMBERS)\n",
    "                else:\n",
    "                    assert False, \"Disagreement measure not implemented\"\n",
    "            disagreement.append(instanceDisagreement)\n",
    "        disagreement = np.asarray(disagreement)\n",
    "        indices = np.argsort(disagreement, axis = 0)[:num_queries]\n",
    "        return X_unlabelled[indices], y_oracle[indices]\n",
    "    else: \n",
    "        assert False, \"Active learning type not implemented\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Model Training without Additional Data\n",
    "\n",
    "Model used is `Naive Bayes Classifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.09507759387280916\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  537   178   259     0  2541   624 21260]\n",
      " [ 2954   873  2912   347  9256  1747 16059]\n",
      " [    0     0  1701  2532     3    10    15]\n",
      " [    0     0     5   341     0     0     0]\n",
      " [    0     3   286     0   668    67   148]\n",
      " [    0     0   635  1141    42   181    21]\n",
      " [    9     0     7     0    23     9  2328]]\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "\n",
    "model.fit(X_labelled, y_labelled)\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, prediction))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for different Active Learning Types with various Information Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_using_al(X_labelled, y_labelled, model, measure, al_type, label_percent):\n",
    "    X_active, y_active = X_labelled.copy(), y_labelled.copy()\n",
    "\n",
    "    queriedData, newLabels = qbc(committee, measure, al_type, label_percent)\n",
    "\n",
    "    X_active = np.concatenate((X_active, queriedData))\n",
    "    y_active = np.concatenate((y_active, newLabels))\n",
    "    \n",
    "    new_model = GaussianNB()\n",
    "\n",
    "    new_model.fit(X_active, y_active)\n",
    "    prediction = new_model.predict(X_test)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, prediction))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream using Vote Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-aa06bbb51c46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmeasure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'voteEntropy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabel_percent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mevaluate_using_al\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_labelled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_labelled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mal_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_percent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-d5a758f6f9d9>\u001b[0m in \u001b[0;36mevaluate_using_al\u001b[0;34m(X_labelled, y_labelled, model, measure, al_type, label_percent)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mX_active\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_active\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_labelled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_labelled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mqueriedData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommittee\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mal_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_percent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mX_active\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_active\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueriedData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-bf1ba493b990>\u001b[0m in \u001b[0;36mqbc\u001b[0;34m(committee, measure, ALtype, labelPercent)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_COMMITTEE_MEMBERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mcommittee_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommittee\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommittee_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_unlabelled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0;31m# vote entropy based disagreement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmeasure\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"voteEntropy\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.5/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.5/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;31m# The weights are all 1. for SAMME.R\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             pred = sum(_samme_proba(estimator, n_classes, X)\n\u001b[0;32m--> 697\u001b[0;31m                        for estimator in self.estimators_)\n\u001b[0m\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# self.algorithm == \"SAMME\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             pred = sum((estimator.predict(X) == classes).T * w\n",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.5/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;31m# The weights are all 1. for SAMME.R\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             pred = sum(_samme_proba(estimator, n_classes, X)\n\u001b[0;32m--> 697\u001b[0;31m                        for estimator in self.estimators_)\n\u001b[0m\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# self.algorithm == \"SAMME\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             pred = sum((estimator.predict(X) == classes).T * w\n",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.5/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_samme_proba\u001b[0;34m(estimator, n_classes, X)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     return (n_classes - 1) * (log_proba - (1. / n_classes)\n\u001b[0;32m--> 282\u001b[0;31m                               * log_proba.sum(axis=1)[:, np.newaxis])\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.5/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m     34\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     35\u001b[0m          initial=_NoValue):\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "al_type = 'stream'\n",
    "measure = 'voteEntropy'\n",
    "label_percent = 0.2\n",
    "evaluate_using_al(X_labelled, y_labelled, model, measure, al_type, label_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream using KL Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.13239723473222226\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  262   453   259     0  5352    19 19054]\n",
      " [   64  3763  2914   345 13837   211 13014]\n",
      " [    0     0  1706  2532     6     3    14]\n",
      " [    0     0     5   341     0     0     0]\n",
      " [    0     3   286     0   763     0   120]\n",
      " [    0     0   651  1140   154    50    25]\n",
      " [    9     0     7     0    14     0  2346]]\n"
     ]
    }
   ],
   "source": [
    "al_type = 'stream'\n",
    "measure = 'KLDivergence'\n",
    "label_percent = 0.1\n",
    "evaluate_using_al(X_labelled, y_labelled, model, measure, al_type, label_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pool using Vote Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7]\n",
      "Accuracy: 0.0924385416367861\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  729    70   233     0  2862  1683 19822]\n",
      " [ 3568   337  2801   351  9924  2175 14992]\n",
      " [    0     0  1797  2404     9    36    15]\n",
      " [    0     0     9   337     0     0     0]\n",
      " [    0     2   211     0   709    89   161]\n",
      " [    0     1   607  1101    53   230    28]\n",
      " [   21     9     7     0    23    10  2306]]\n"
     ]
    }
   ],
   "source": [
    "al_type = 'pool'\n",
    "measure = 'voteEntropy'\n",
    "label_percent = 0.1\n",
    "evaluate_using_al(X_labelled, y_labelled, model, measure, al_type, label_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pool using KL Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7]\n",
      "Accuracy: 0.0924385416367861\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  729    70   233     0  2862  1683 19822]\n",
      " [ 3568   337  2801   351  9924  2175 14992]\n",
      " [    0     0  1797  2404     9    36    15]\n",
      " [    0     0     9   337     0     0     0]\n",
      " [    0     2   211     0   709    89   161]\n",
      " [    0     1   607  1101    53   230    28]\n",
      " [   21     9     7     0    23    10  2306]]\n"
     ]
    }
   ],
   "source": [
    "al_type = 'pool'\n",
    "measure = 'KLDivergence'\n",
    "label_percent = 0.1\n",
    "evaluate_using_al(X_labelled, y_labelled, model, measure, al_type, label_percent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
