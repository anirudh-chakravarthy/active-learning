{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream and Pool Active Learning using Uncertainty Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Breast Cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "x, y = fetch_covtype(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing, scale features between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the whole dataset in train & test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.40, random_state = 4)\n",
    "\n",
    "# further divide the train data in labelled & unlabelled data\n",
    "# retain only 3% of labelled points for training\n",
    "NUM_EXAMPLES = len(X_train)\n",
    "X_labelled, X_unlabelled, y_labelled, y_oracle = train_test_split(X_train, y_train, test_size = 0.90, random_state = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty Sampling Implementation\n",
    "Information measures used:\n",
    "- Least Confident\n",
    "- Margin Sampling\n",
    "- Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertaintySampling(model, measure, ALtype, labelPercent):\n",
    "\n",
    "    probabilities = model.predict_proba(X_unlabelled)\n",
    "\n",
    "    # stream-based active learning\n",
    "    if ALtype == \"stream\":\n",
    "        queriedData, newLabels = [], []\n",
    "        # stream of points - one by one\n",
    "        num_queries = int(NUM_EXAMPLES * labelPercent)\n",
    "        for i in range(len(X_unlabelled)):\n",
    "            if i == num_queries:\n",
    "                break\n",
    "            # return all points with confidence threshold\n",
    "            if measure == \"leastConfident\":\n",
    "                if probabilities[i].max() < 0.6:\n",
    "                    queriedData.append(X_unlabelled[i])\n",
    "                    newLabels.append(y_oracle[i])\n",
    "            # return all points with margin threshold\n",
    "            elif measure == \"marginSampling\":\n",
    "                sortedProbabilities = np.sort(probabilities[i])\n",
    "                margin = abs(sortedProbabilities[1] - sortedProbabilities[0])\n",
    "                if margin < 0.2:\n",
    "                    queriedData.append(X_unlabelled[i])\n",
    "                    newLabels.append(y_oracle[i])\n",
    "            # return all points with entropy threshold\n",
    "            elif measure == \"entropy\":\n",
    "#                 print(probabilities[i])\n",
    "                entropy = -np.sum(probabilities[i] * np.log2(probabilities[i] + 1e-100))\n",
    "#                 print(entropy)\n",
    "                if entropy > 0.99:\n",
    "                    queriedData.append(X_unlabelled[i])\n",
    "                    newLabels.append(y_oracle[i])\n",
    "            else:\n",
    "                assert False, \"Information measure not implemented\"\n",
    "        return np.asarray(queriedData), np.asarray(newLabels)\n",
    "\n",
    "    \n",
    "    # pool-based active learning\n",
    "    elif ALtype == \"pool\":\n",
    "        # return labelPercent points of all points\n",
    "        num_queries = int(NUM_EXAMPLES * labelPercent)\n",
    "        if measure == \"leastConfident\":\n",
    "            sortedProbabilities = np.argsort(probabilities.max(axis=1))\n",
    "            indices = sortedProbabilities[-num_queries:]\n",
    "        elif measure == \"marginSampling\":\n",
    "            sortedProbabilities = np.sort(probabilities)\n",
    "            indices = np.argsort(sortedProbabilities[:, -2] - sortedProbabilities[:, -1])[:num_queries]\n",
    "        elif measure == \"entropy\":\n",
    "            entropies = -np.sum(probabilities * np.log2(probabilities + 1e-100), axis=1)\n",
    "            indices = np.argsort(entropies)[:num_queries]\n",
    "        else:\n",
    "            assert False, \"Information measure not implemented\"            \n",
    "        return X_unlabelled[indices], y_oracle[indices]\n",
    "\n",
    "    else:\n",
    "        assert False, \"Active learning type not implemented\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Model Training without Additional Data\n",
    "\n",
    "Model used is `Naive Bayes Classifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.09537660549471827\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2987   130   833     0 19534   813 60517]\n",
      " [13070   895  9629  1239 45354  1240 41955]\n",
      " [    0     0  6134  8024    59    46     5]\n",
      " [    0     0    33  1057     0     0     0]\n",
      " [    0     3   996     0  2590    27   206]\n",
      " [    0     0  2446  3475   367   496     5]\n",
      " [    4     0    32     0   197     0  8007]]\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "\n",
    "model.fit(X_labelled, y_labelled)\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, prediction))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for different Active Learning Types with various Information Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_using_al(X_labelled, y_labelled, model, measure, al_type, label_percent):\n",
    "    X_active, y_active = X_labelled.copy(), y_labelled.copy()\n",
    "\n",
    "    queriedData, newLabels = uncertaintySampling(model, measure, al_type, label_percent)\n",
    "\n",
    "    X_active = np.concatenate((X_active, queriedData))\n",
    "    y_active = np.concatenate((y_active, newLabels))\n",
    "    \n",
    "    new_model = GaussianNB()\n",
    "\n",
    "    new_model.fit(X_active, y_active)\n",
    "    prediction = new_model.predict(X_test)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, prediction))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream using Least Confident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.09588003700436738\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2983   130   833     0 19710   868 60290]\n",
      " [13064   895  9629  1239 46081  1517 40957]\n",
      " [    0     0  6134  8024    62    46     2]\n",
      " [    0     0    33  1057     0     0     0]\n",
      " [    0     3   996     0  2678    32   113]\n",
      " [    0     0  2446  3475   344   519     5]\n",
      " [    4     0    32     0   187     0  8017]]\n"
     ]
    }
   ],
   "source": [
    "al_type = 'stream'\n",
    "measure = 'leastConfident'\n",
    "label_percent = 0.1\n",
    "evaluate_using_al(X_labelled, y_labelled, model, measure, al_type, label_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream using Margin Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0908112992405499\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2635   163   833     0 17892   729 62562]\n",
      " [12401   550  9629  1239 45224   845 43494]\n",
      " [    0     0  5763  8395    59    46     5]\n",
      " [    0     0    14  1076     0     0     0]\n",
      " [    0     0   996     0  2561    24   241]\n",
      " [    0     0  2224  3697   404   459     5]\n",
      " [    4     0    32     0   143     0  8061]]\n"
     ]
    }
   ],
   "source": [
    "al_type = 'stream'\n",
    "measure = 'marginSampling'\n",
    "evaluate_using_al(X_labelled, y_labelled, model, measure, al_type, label_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream using Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.09575955766872485\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2985   130   833     0 19674   822 60370]\n",
      " [13064   895  9629  1239 45951  1303 41301]\n",
      " [    0     0  6134  8024    62    46     2]\n",
      " [    0     0    33  1057     0     0     0]\n",
      " [    0     3   996     0  2663    27   133]\n",
      " [    0     0  2446  3475   354   509     5]\n",
      " [    4     0    32     0   192     0  8012]]\n"
     ]
    }
   ],
   "source": [
    "al_type = 'stream'\n",
    "measure = 'entropy'\n",
    "evaluate_using_al(X_labelled, y_labelled, model, measure, al_type, label_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pool using Least Confident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1834297885157376\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13863  1362   833     0 49866   544 18346]\n",
      " [ 4726 11920  9616  1252 72873   381 12614]\n",
      " [    0     0  5680  8107    40   417    24]\n",
      " [    0     0     0  1071     0    19     0]\n",
      " [    0     3   996     0  2606    24   193]\n",
      " [    0     0  2107  3592   622   465     3]\n",
      " [  123     0    32     0  1060     0  7025]]\n"
     ]
    }
   ],
   "source": [
    "al_type = 'pool'\n",
    "measure = 'leastConfident'\n",
    "label_percent = 0.3\n",
    "evaluate_using_al(X_labelled, y_labelled, model, measure, al_type, label_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pool using Margin Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1758223790365956\n",
      "\n",
      "Confusion Matrix:\n",
      "[[12092  1362   833     0 57539   544 12444]\n",
      " [ 3976 11920  9618  1250 84004   381  2233]\n",
      " [    0     0  6067  8091    64    46     0]\n",
      " [    0     0    19  1071     0     0     0]\n",
      " [    0     3   996     0  2799    24     0]\n",
      " [    0     0  2329  3592   625   243     0]\n",
      " [  123     0    32     0  1415     0  6670]]\n"
     ]
    }
   ],
   "source": [
    "al_type = 'pool'\n",
    "measure = 'marginSampling'\n",
    "label_percent = 0.2\n",
    "evaluate_using_al(X_labelled, y_labelled, model, measure, al_type, label_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pool using Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.20475032809104796\n",
      "\n",
      "Confusion Matrix:\n",
      "[[14746  1362   833     0 57577   545  9751]\n",
      " [ 4966 11920 10437   431 84004   381  1243]\n",
      " [    0     0 10121  3748    64   335     0]\n",
      " [    0     0   157   914     0    19     0]\n",
      " [    0     3   996     0  2799    24     0]\n",
      " [    0     0  4388  1347   625   429     0]\n",
      " [  137     0    32     0  1415     0  6656]]\n"
     ]
    }
   ],
   "source": [
    "al_type = 'pool'\n",
    "measure = 'entropy'\n",
    "label_percent = 0.2\n",
    "evaluate_using_al(X_labelled, y_labelled, model, measure, al_type, label_percent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
